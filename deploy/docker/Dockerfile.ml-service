# deploy/docker/Dockerfile.ml-service
#
# Build + run the FastAPI-based ML verification service.
# Assumes:
#   - workspace root has a `ml_service/` directory
#   - `ml_service/pyproject.toml`
#   - `ml_service/src/` with `main.py` and friends

FROM python:3.11-slim

WORKDIR /app/ml_service

# Install system deps you might need later (kept minimal for now).
RUN apt-get update && \
    apt-get install -y --no-install-recommends gcc && \
    rm -rf /var/lib/apt/lists/*

# Copy Python project metadata and source.
COPY ml_service/pyproject.toml .
COPY ml_service/src ./src

# Install the package in the container.
RUN pip install --no-cache-dir .

# Default model root (matches src/config.py default + config/ml-service.toml).
ENV ML_SERVICE_MODEL_ROOT=/app/ml_service/models

# Ensure the models directory exists.
RUN mkdir -p /app/ml_service/models

EXPOSE 8080

# Run the FastAPI app with uvicorn.
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8080"]
